{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('house-prices': conda)",
   "display_name": "Python 3.7.9 64-bit ('house-prices': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4298b73e519f2fdd4ef70e94b093e234e5f2152505a72ace6b261e020e5cb87e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "X = train.drop(['Id', 'target'], axis=1)\n",
    "X_test = test.drop(['Id', 'target'], axis=1)\n",
    "\n",
    "y = train['target'].values\n",
    "y_test = test['target'].values\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X, y)\n",
    "lgb_test = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1]\tvalid_0's l1: 0.29413\tvalid_0's l2: 0.145976\nTraining until validation scores don't improve for 5 rounds\n[2]\tvalid_0's l1: 0.281992\tvalid_0's l2: 0.135259\n[3]\tvalid_0's l1: 0.270315\tvalid_0's l2: 0.125245\n[4]\tvalid_0's l1: 0.259566\tvalid_0's l2: 0.116378\n[5]\tvalid_0's l1: 0.24962\tvalid_0's l2: 0.10849\n[6]\tvalid_0's l1: 0.239864\tvalid_0's l2: 0.100928\n[7]\tvalid_0's l1: 0.230605\tvalid_0's l2: 0.0941316\n[8]\tvalid_0's l1: 0.221819\tvalid_0's l2: 0.0879086\n[9]\tvalid_0's l1: 0.213935\tvalid_0's l2: 0.0824875\n[10]\tvalid_0's l1: 0.206366\tvalid_0's l2: 0.077347\n[11]\tvalid_0's l1: 0.199575\tvalid_0's l2: 0.0728097\n[12]\tvalid_0's l1: 0.193512\tvalid_0's l2: 0.068906\n[13]\tvalid_0's l1: 0.187442\tvalid_0's l2: 0.0651338\n[14]\tvalid_0's l1: 0.181828\tvalid_0's l2: 0.0617804\n[15]\tvalid_0's l1: 0.176542\tvalid_0's l2: 0.0586052\n[16]\tvalid_0's l1: 0.170552\tvalid_0's l2: 0.055355\n[17]\tvalid_0's l1: 0.165216\tvalid_0's l2: 0.0524908\n[18]\tvalid_0's l1: 0.160125\tvalid_0's l2: 0.0498185\n[19]\tvalid_0's l1: 0.155434\tvalid_0's l2: 0.0474634\n[20]\tvalid_0's l1: 0.151183\tvalid_0's l2: 0.0452997\n[21]\tvalid_0's l1: 0.147307\tvalid_0's l2: 0.0433937\n[22]\tvalid_0's l1: 0.143783\tvalid_0's l2: 0.0417562\n[23]\tvalid_0's l1: 0.140328\tvalid_0's l2: 0.0402704\n[24]\tvalid_0's l1: 0.137139\tvalid_0's l2: 0.0388826\n[25]\tvalid_0's l1: 0.133923\tvalid_0's l2: 0.0374845\n[26]\tvalid_0's l1: 0.131035\tvalid_0's l2: 0.0362038\n[27]\tvalid_0's l1: 0.128478\tvalid_0's l2: 0.0350944\n[28]\tvalid_0's l1: 0.126309\tvalid_0's l2: 0.0340922\n[29]\tvalid_0's l1: 0.124083\tvalid_0's l2: 0.0332518\n[30]\tvalid_0's l1: 0.12199\tvalid_0's l2: 0.0324237\n[31]\tvalid_0's l1: 0.119988\tvalid_0's l2: 0.0315544\n[32]\tvalid_0's l1: 0.117966\tvalid_0's l2: 0.0307381\n[33]\tvalid_0's l1: 0.116278\tvalid_0's l2: 0.0300446\n[34]\tvalid_0's l1: 0.114513\tvalid_0's l2: 0.0293552\n[35]\tvalid_0's l1: 0.112914\tvalid_0's l2: 0.0286947\n[36]\tvalid_0's l1: 0.111097\tvalid_0's l2: 0.0280328\n[37]\tvalid_0's l1: 0.109664\tvalid_0's l2: 0.0275161\n[38]\tvalid_0's l1: 0.108312\tvalid_0's l2: 0.0269948\n[39]\tvalid_0's l1: 0.106899\tvalid_0's l2: 0.0264903\n[40]\tvalid_0's l1: 0.10578\tvalid_0's l2: 0.0260926\n[41]\tvalid_0's l1: 0.104302\tvalid_0's l2: 0.0255627\n[42]\tvalid_0's l1: 0.103088\tvalid_0's l2: 0.0251452\n[43]\tvalid_0's l1: 0.102255\tvalid_0's l2: 0.0248484\n[44]\tvalid_0's l1: 0.101115\tvalid_0's l2: 0.0244734\n[45]\tvalid_0's l1: 0.100096\tvalid_0's l2: 0.0241538\n[46]\tvalid_0's l1: 0.0994347\tvalid_0's l2: 0.0239463\n[47]\tvalid_0's l1: 0.0988888\tvalid_0's l2: 0.023659\n[48]\tvalid_0's l1: 0.0980521\tvalid_0's l2: 0.023368\n[49]\tvalid_0's l1: 0.0973766\tvalid_0's l2: 0.0231374\n[50]\tvalid_0's l1: 0.097106\tvalid_0's l2: 0.0229939\n[51]\tvalid_0's l1: 0.096353\tvalid_0's l2: 0.0227799\n[52]\tvalid_0's l1: 0.0956163\tvalid_0's l2: 0.0225823\n[53]\tvalid_0's l1: 0.0948916\tvalid_0's l2: 0.0223835\n[54]\tvalid_0's l1: 0.0944404\tvalid_0's l2: 0.0221966\n[55]\tvalid_0's l1: 0.0939031\tvalid_0's l2: 0.022069\n[56]\tvalid_0's l1: 0.0935368\tvalid_0's l2: 0.021956\n[57]\tvalid_0's l1: 0.0929221\tvalid_0's l2: 0.0217304\n[58]\tvalid_0's l1: 0.0925376\tvalid_0's l2: 0.0216047\n[59]\tvalid_0's l1: 0.0922183\tvalid_0's l2: 0.0214813\n[60]\tvalid_0's l1: 0.0917917\tvalid_0's l2: 0.0213551\n[61]\tvalid_0's l1: 0.0914146\tvalid_0's l2: 0.0212819\n[62]\tvalid_0's l1: 0.0908675\tvalid_0's l2: 0.0211361\n[63]\tvalid_0's l1: 0.0905157\tvalid_0's l2: 0.02107\n[64]\tvalid_0's l1: 0.0900844\tvalid_0's l2: 0.020955\n[65]\tvalid_0's l1: 0.0899216\tvalid_0's l2: 0.0209072\n[66]\tvalid_0's l1: 0.089481\tvalid_0's l2: 0.0207902\n[67]\tvalid_0's l1: 0.0893099\tvalid_0's l2: 0.0207383\n[68]\tvalid_0's l1: 0.0889971\tvalid_0's l2: 0.0206618\n[69]\tvalid_0's l1: 0.0888005\tvalid_0's l2: 0.020605\n[70]\tvalid_0's l1: 0.0887246\tvalid_0's l2: 0.0205559\n[71]\tvalid_0's l1: 0.0884096\tvalid_0's l2: 0.0205401\n[72]\tvalid_0's l1: 0.0882914\tvalid_0's l2: 0.0204955\n[73]\tvalid_0's l1: 0.0880953\tvalid_0's l2: 0.0204501\n[74]\tvalid_0's l1: 0.0879819\tvalid_0's l2: 0.0204131\n[75]\tvalid_0's l1: 0.0879252\tvalid_0's l2: 0.0203995\n[76]\tvalid_0's l1: 0.0875973\tvalid_0's l2: 0.0203029\n[77]\tvalid_0's l1: 0.0872315\tvalid_0's l2: 0.0201956\n[78]\tvalid_0's l1: 0.0869305\tvalid_0's l2: 0.0201007\n[79]\tvalid_0's l1: 0.0867739\tvalid_0's l2: 0.0200166\n[80]\tvalid_0's l1: 0.0865365\tvalid_0's l2: 0.0199252\n[81]\tvalid_0's l1: 0.0863682\tvalid_0's l2: 0.0198635\n[82]\tvalid_0's l1: 0.0862182\tvalid_0's l2: 0.0198496\n[83]\tvalid_0's l1: 0.0862689\tvalid_0's l2: 0.0198409\n[84]\tvalid_0's l1: 0.0860261\tvalid_0's l2: 0.0197874\n[85]\tvalid_0's l1: 0.085801\tvalid_0's l2: 0.0197299\n[86]\tvalid_0's l1: 0.085635\tvalid_0's l2: 0.0196451\n[87]\tvalid_0's l1: 0.0854675\tvalid_0's l2: 0.0195762\n[88]\tvalid_0's l1: 0.0852188\tvalid_0's l2: 0.0194969\n[89]\tvalid_0's l1: 0.0852182\tvalid_0's l2: 0.0194514\n[90]\tvalid_0's l1: 0.0850827\tvalid_0's l2: 0.0193988\n[91]\tvalid_0's l1: 0.0849556\tvalid_0's l2: 0.0193617\n[92]\tvalid_0's l1: 0.0848489\tvalid_0's l2: 0.0193324\n[93]\tvalid_0's l1: 0.0848844\tvalid_0's l2: 0.0193667\n[94]\tvalid_0's l1: 0.0847805\tvalid_0's l2: 0.0193469\n[95]\tvalid_0's l1: 0.0847235\tvalid_0's l2: 0.0193347\n[96]\tvalid_0's l1: 0.0847325\tvalid_0's l2: 0.0193208\n[97]\tvalid_0's l1: 0.084798\tvalid_0's l2: 0.0193171\n[98]\tvalid_0's l1: 0.0848066\tvalid_0's l2: 0.0193054\n[99]\tvalid_0's l1: 0.0847505\tvalid_0's l2: 0.0192928\n[100]\tvalid_0's l1: 0.0848375\tvalid_0's l2: 0.0192967\nEarly stopping, best iteration is:\n[95]\tvalid_0's l1: 0.0847235\tvalid_0's l2: 0.0193347\n"
    }
   ],
   "source": [
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'seed': 1337,\n",
    "    'verbose': 0}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                valid_sets=lgb_test,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "pred = gbm.predict(X, num_iteration=gbm.best_iteration)\n",
    "pred_test = gbm.predict(X_test, num_iterations=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train rmse: 0.07587639060115457\ntest rmse: 0.13904910160543832\n"
    }
   ],
   "source": [
    "print('train rmse:', mean_squared_error(y, pred, squared=False))\n",
    "print('test rmse:', mean_squared_error(y_test, pred_test, squared=False))"
   ]
  }
 ]
}